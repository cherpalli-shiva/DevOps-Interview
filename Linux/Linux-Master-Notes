
Linux Fundamentals: Operating System, Architecture, and Core Concepts

1. What is Linux?
Linux is a Unix-like, free, and open-source operating system (OS) developed by Linus Torvalds. It serves as a "bridge that connects the software (apps) with the hardware (CPU, RAM, disk, etc.)," managing all interactions between them. It is widely used in DevOps, cloud computing, server management, and embedded devices.

Key Features of Linux:
Free & Open Source: "Unlike Windows (which you need to buy), Linux is free." It is also open-source, allowing anyone to modify or improve it.

Security: Linux is "inherently more secure than Windows" and generally "doesn’t allow unauthorized access easily," often negating the need for antivirus software.

Distributions (Flavors): Linux offers various versions, known as distributions (distros), tailored for different purposes and user skill levels. Popular examples include: Ubuntu (user-friendly, good for beginners), Red Hat Enterprise Linux (RHEL) (popular in enterprises), CentOS (replaced by AlmaLinux/Rocky Linux in servers), Debian, Alpine, Fedora, Arch Linux.

Speed & Stability: Linux is known for being "fast and doesn’t slow down over time" and is "stable, meaning it doesn’t crash often—perfect for running servers and applications."

Software Development: "Almost every application in DevOps runs on Linux." It's utilized across production, testing, and development environments.

Personal Software Repository: Linux distributions often come with their own software repositories for easy package management.

Multilingual Support: Supports multiple languages and different language keyboards globally.
CLI and GUI: Offers both Command Line Interface (CLI) and Graphical User Interface (GUI) for interaction.

2.Basic Architecture of Linux (Components)
Linux consists of several interconnected components that work together:
Kernel: The kernel is the core of Linux. It's a low-level software system that directly communicates with hardware (CPU, memory, devices). It manages:
Device management (e.g., USB, keyboard)
Memory management (allocates RAM)
Process management (controls running applications)
System calls (allows applications to communicate with the kernel).
It also tracks the resources and provides a user interface.

Shell: Shell is an interface between a kernel and a user. It takes user commands (via CLI) and translates them into instructions for the kernel. Common shells include bash (default), sh, ksh, zsh, and fish.
System Libraries: These are  pre-written functions that help applications communicate with the kernel. Example: libc for file handling.
User Space: This is where users interact with the system and applications run. It includes:
Shell (Command Line Interface)
Compilers (to run code)
User processes (applications like Jenkins, MySQL, Apache).
GUI (Graphical User Interface): Offers a "different way to interact with the system," using icons, menus, and windows, manipulable via a mouse.
Application Programs: Software designed "to perform a bundle of tasks through a bundle of functions" (e.g., MS Word, Chrome, Jenkins).
System Utilities: "Software functions through which users manage the system" (e.g., ls, cp, mv).

3. Hardware and Software
Hardware: "The physical parts of a computer — things you can touch." Examples: CPU, RAM, Hard Drive/SSD, Motherboard, Monitor, Keyboard, Mouse, Network Card.

Software: "The set of instructions (code/programs) that tell hardware what to do." It's intangible but runnable.

System Software: Controls hardware and provides a platform (e.g., Linux OS).
Application Software: Used for specific user tasks (e.g., MS Word, Chrome).
Programming Software: Tools for developing programs (e.g., code editors, compilers like GCC, IDEs).

4. Shell Scripting and its Role in DevOps
Shell scripting involves writing "a sequence of commands in a file to automate tasks, such as backups or log analysis." It saves time and reduces human errors in repetitive tasks. Since servers typically lack a graphical interface, "shell commands are the only way to interact with them."

Role in DevOps: DevOps engineers heavily rely on shell scripting for:
Infrastructure Maintenance: Automating server setup.
Code Management: Interacting with Git repositories.
Configuration Management: Managing system configurations.
Task Automation: Scheduling tasks with cron jobs.
System Monitoring: Checking CPU/memory usage.

The Shebang (#!/bin/bash): The first line in a shell script, #!/bin/bash, is crucial. It "tells the system which shell should be used to execute the script." Different shells include /bin/sh, /bin/bash, /bin/ksh, and /bin/dash.

Essential Linux Commands & Utilities
The sources provide an extensive list of commands, categorized for clarity.
1. File and Directory Management
These commands help you navigate, create, modify, and delete files and directories within the Linux file system.
• ls (List directory contents)
    ◦ Purpose: Lists files and directories in the current directory or a specified path.
    ◦ Explanation: It's one of the most basic and frequently used commands. By default, it shows contents of the current directory.
    ◦ Key Options:
        ▪ -l (long listing format): Displays files with detailed information, including permissions, owner, group, size, and date modified.
        ▪ -a (all): Shows hidden files (those starting with a dot .) in addition to visible ones.
        ▪ -h (human-readable): Displays file sizes in easily understandable units (e.g., KB, MB, GB) when used with -l.
        ▪ -t (time sort): Sorts files by modification time, newest first.
        ▪ -r (reverse): Reverses the order of the sort.
    ◦ Examples:
        ▪ ls: List files and folders in the current directory.
        ▪ ls -ltr: Show files with details, sorted by time in reverse order.
        ▪ ls -a: Display hidden files.
• cd (Change directory)
    ◦ Purpose: Changes the current working directory.
    ◦ Explanation: This command is essential for navigating the file system.
    ◦ Key Usage:
        ▪ cd <directory_name>: Moves into a specified directory.
        ▪ cd ..: Moves one level up to the parent directory.
        ▪ cd /: Changes to the root directory.
        ▪ cd ~ or cd: Changes to the current user's home directory.
    ◦ Examples:
        ▪ cd myfolder: Change to myfolder.
        ▪ cd ../../: Move two steps back (two levels up).
• pwd (Print working directory)
    ◦ Purpose: Displays the absolute path of the current working directory.
    ◦ Explanation: Useful for knowing exactly where you are in the file system hierarchy.
• mkdir (Make directories)
    ◦ Purpose: Creates one or more new directories.
    ◦ Explanation: Simple command to organize your files into folders.
    ◦ Example: mkdir myfolder: Creates a directory named myfolder.
• rm (Remove files or directories)
    ◦ Purpose: Deletes files or directories.
    ◦ Key Options:
        ▪ -f (force): Removes files without prompting for confirmation, even if they are write-protected.
        ▪ -r (recursive): Required to remove directories and their contents. Use with caution as it permanently deletes data.
    ◦ Examples:
        ▪ rm myfile.txt: Deletes myfile.txt.
        ▪ rm -r myfolder: Deletes myfolder and all its contents.
        ▪ rm -rf important_data: Forcefully deletes important_data directory and everything inside it without prompting.
• cp (Copy files and directories)
    ◦ Purpose: Copies files or directories from one location to another.
    ◦ Key Option:
        ▪ -r (recursive): Essential for copying directories and their contents.
    ◦ Examples:
        ▪ cp file1.txt file2.txt: Copies file1.txt to file2.txt in the current directory.
        ▪ cp -R source_directory destination_directory: Recursively copies a directory and its contents.
• mv (Move or rename files and directories)
    ◦ Purpose: Moves files or directories from one location to another, or renames them if staying in the same location.
    ◦ Examples:
        ▪ mv oldname.txt newname.txt: Renames oldname.txt to newname.txt.
        ▪ mv myfile.txt /path/to/new/location/: Moves myfile.txt to a new directory.
• touch (Change file timestamps or create empty files)
    ◦ Purpose: Creates an empty file if it doesn't exist, or updates the access and modification timestamps of an existing file.
    ◦ Examples:
        ▪ touch myfile.txt: Creates an empty file named myfile.txt.
        ▪ touch .hidden.txt: Creates a hidden file.

2. File Viewing and Editing
These commands allow you to view the content of files, search for specific text, and perform basic text editing in the terminal.
• cat (Concatenate and display file content)
    ◦ Purpose: Displays the entire content of a file to standard output. It can also be used to create new files or append data.
    ◦ Key Options/Usage:
        ▪ cat > filename: Creates a new file and allows you to input data, pressing Ctrl+D to save and exit.
        ▪ cat >> filename: Appends data to an existing file.
        ▪ -b: Adds line numbers to non-blank lines.
        ▪ -n: Adds line numbers to all lines, including blank ones.
    ◦ Examples:
        ▪ cat myfile.txt: Displays the content of myfile.txt.
        ▪ cat > new.txt: Create new.txt and add content.
        ▪ cat -n script.sh: Displays script.sh with line numbers.
• head (Output the first part of a file)
    ◦ Purpose: Displays the first few lines of a file. By default, it shows the first 10 lines.
    ◦ Key Option: -n <number>: Specifies the number of lines to display.
    ◦ Example: head -n 5 file.txt: Shows the first 5 lines of file.txt.

• tail (Output the last part of a file)
    ◦ Purpose: Displays the last few lines of a file. By default, it shows the last 10 lines.
    ◦ Key Options:
        ▪ -n <number>: Specifies the number of lines to display.
        ▪ -f (follow): Continuously monitors the file and displays new lines as they are added, commonly used for log files.
    ◦ Examples:
        ▪ tail -n 3 file.txt: Shows the last 3 lines of file.txt.
        ▪ tail -f /var/log/syslog: Monitors syslog in real-time.

• vi / vim (Advanced text editor)
    ◦ Purpose: A powerful, terminal-based text editor widely available on Linux systems. It operates in different modes.
    ◦ Key Modes:
        ▪ Command Mode: (Default upon opening) Used for navigation, deleting, copying, pasting, and saving/quitting.
        ▪ Insert Mode: (Accessed by pressing i, a, o, etc.) Allows typing and editing text.
        ▪ Visual Mode: (Accessed by pressing v) Used for selecting text.
    ◦ Common Commands (from Command Mode):
        ▪ i: Enter insert mode before the cursor.
        ▪ Esc: Exit insert mode back to command mode.
        ▪ :w: Save the file.
        ▪ :q!: Quit without saving.
        ▪ :wq: Save and quit.
        ▪ :linenumber (e.g., :10): Go to a specific line.
        ▪ /$word: Search for a word.
        ▪ %s/old_word/new_word/g: Replace all occurrences of old_word with new_word globally in the file.
        ▪ 20,30s/madhu/lalita: Replace madhu with lalita between lines 20 and 30.

• grep (Search text using patterns)
    ◦ Purpose: Searches for lines containing a specified pattern in files.
    ◦ Key Options:
        ▪ -i (ignore case): Performs a case-insensitive search.
        ▪ -o (only matching): Prints only the matching part of the lines.
        ▪ -r (recursive): Searches directories recursively.
        ▪ -c (count): Outputs a count of matching lines.
    ◦ Examples:
        ▪ grep "test" file.txt: Searches for "test" in file.txt.
        ▪ grep -i word file.txt: Searches for "word" (case-insensitive) in file.txt.
        ▪ grep -r "error" /var/log/: Recursively searches for "error" in /var/log directory.
• sed (Stream editor for filtering and transforming text)
    ◦ Purpose: Used for basic text transformations on files or input streams. It's excellent for search and replace operations.
    ◦ Example: sed 's/old/new/g' file.txt: Replaces all occurrences of "old" with "new" in file.txt.

• awk (Pattern scanning and processing language)
    ◦ Purpose: A powerful text processing tool for pattern scanning and processing. It's often used for extracting and manipulating data from structured text files.
    ◦ Example: awk '{print $1}' file.txt: Prints the first column of each line in file.txt.

• cut (Remove sections from each line of files)
    ◦ Purpose: Extracts specific fields or characters from each line of a file.
    ◦ Key Options:
        ▪ -d <delimiter>: Specifies the field delimiter (e.g., ,, :).
        ▪ -f <field_number>: Specifies the field(s) to extract.
        ▪ -c <character_range>: Specifies the character range to extract.
    ◦ Examples:
        ▪ cut -d ':' -f 1 /etc/passwd: Prints the first field (username) from /etc/passwd using : as a delimiter.
        ▪ cut -c 1-5 emp.txt: Extracts characters from position 1 to 5 from emp.txt.
• sort (Sort lines of text files)
    ◦ Purpose: Sorts the lines of text files.
    ◦ Key Options:
        ▪ -r (reverse): Sorts in reverse order.
        ▪ -f (ignore case): Sorts without caring about case sensitivity.
        ▪ -n (numeric sort): Sorts numerical data based on their true mathematical value.
        ▪ -t <delimiter>: Specifies a field separator (delimiter).
        ▪ -k <key_position>: Sorts based on a specific column (key).
    ◦ Examples:
        ▪ sort file.txt: Sorts file.txt content in ascending order.
        ▪ sort -t "," -k3 data.txt: Sorts data.txt by the third comma-separated column.

• wc (Word, line, character, and byte count)
    ◦ Purpose: Counts lines, words, and characters in a file.
    ◦ Key Options:
        ▪ -l: Counts only lines.
        ▪ -w: Counts only words.
        ▪ -c: Counts only characters (bytes).
    ◦ Example: wc -l myfile.txt: Counts the number of lines in myfile.txt.

3. Process Management
These commands help you view, control, and terminate processes running on your Linux system.
• ps (Report a snapshot of current processes)
    ◦ Purpose: Displays information about currently running processes. It provides a static snapshot, unlike top or htop.
    ◦ Key Options:
        ▪ -e (every process): Displays all processes.
        ▪ -f (full format): Shows a detailed list of processes, including PID, PPID, CPU/memory usage, start time, and command.
        ▪ aux (all users, with command): A common combination for a detailed list of all processes run by all users.
    ◦ Examples:
        ▪ ps: Shows processes in the current shell.
        ▪ ps -f: Displays a detailed list of processes.
        ▪ ps aux: Lists all running processes, including those of other users.

• top (Display Linux tasks)
    ◦ Purpose: Provides a real-time, dynamic overview of system resource usage, including CPU, memory, and running processes.
    ◦ Explanation: It continuously updates, showing CPU and memory usage by process, helping identify resource hogs.
    ◦ Key Information: Displays PID, user, CPU usage (%), memory usage (%), command.
    ◦ Example: top: Opens the interactive process viewer.

• htop (Interactive process viewer)
    ◦ Purpose: An enhanced and more user-friendly version of top.
    ◦ Explanation: Offers a color-coded list, easier navigation, and additional features like sorting and filtering. It provides a more intuitive graphical representation of CPU usage with colored bars.
    ◦ Example: htop: Opens the interactive process viewer.

• kill (Send a signal to a process)
    ◦ Purpose: Sends a signal to a process, typically to terminate it. You usually need the Process ID (PID).
    ◦ Key Signals:
        ▪ -9 (SIGKILL): Forcefully terminates a process (cannot be ignored).
        ▪ -15 (SIGTERM): Graceful termination (allows process to clean up before exiting).
        ▪ -19 (SIGSTOP): Pauses a process.
        ▪ -18 (SIGCONT): Resumes a paused process.
        ▪ -l (list): Lists available signal names and numbers.
    ◦ Examples:
        ▪ kill <PID>: Terminates a process gracefully.
        ▪ kill -9 <PID>: Forcefully kills a process.
        ▪ kill -l: Lists all available signals.

• nohup (Run commands that continue after user logs out)
    ◦ Purpose: Runs a command or script that will continue running even after the user logs out or terminates the session ("no hangup").
    ◦ Example: nohup ./script.sh &: Executes script.sh in the background, detached from the terminal. The & symbol sends the script to the background.

• uptime (Show how long the system has been running)
    ◦ Purpose: Displays how long the system has been running, including current time, number of logged-in users, and load averages.
    ◦ Examples:
        ▪ uptime: Shows system uptime.
        ▪ uptime -s: Shows system boot time and date.

4. Disk Management
These commands help you monitor disk space, usage, and manage file systems.
• df (Report file system disk space usage)
    ◦ Purpose: Displays information about total, used, and available disk space on file systems.
    ◦ Key Option: -h (human-readable): Shows disk usage in easily understandable units (e.g., GB, MB).
    ◦ Example: df -h: Shows disk space usage in human-readable format.
• du (Estimate file space usage)
    ◦ Purpose: Estimates and shows the disk space usage of files and directories.
    ◦ Key Options:
        ▪ -h (human-readable): Displays sizes in human-readable format.
        ▪ -s (summary): Displays a total for each argument.
    ◦ Examples:
        ▪ du -h: Shows disk usage for the current directory in human-readable format.
        ▪ du -sh ~/Documents: Shows the total disk usage for the Documents directory.
• mount / umount (Mount or unmount file systems)
    ◦ Purpose:
        ▪ mount: Makes a filesystem accessible to the operating system by associating it with a directory (mount point).
        ▪ umount: Detaches the mounted filesystem from its mount point.
    ◦ Examples:
        ▪ sudo mount /dev/sda1 /mnt/data: Mounts the /dev/sda1 partition to /mnt/data.
        ▪ sudo umount /mnt/data: Unmounts the filesystem from /mnt/data.

5. Networking
These commands are crucial for checking network connectivity, configuring network interfaces, and transferring files over the network.
• ping (Check connectivity)
    ◦ Purpose: Sends ICMP Echo requests to network hosts to check network connectivity and measure round-trip time.
    ◦ Explanation: Used to verify if a remote host is reachable.
    ◦ Example: ping google.com: Checks connectivity to google.com.

• ip (Show/manipulate routing, devices, and tunnels)
    ◦ Purpose: A modern and more powerful command for configuring network interfaces, routing tables, and network protocols. It largely replaces ifconfig.
    ◦ Key Usage:
        ▪ ip addr: Shows IP addresses for all network interfaces.
        ▪ ip link: Shows or manipulates network interfaces.
        ▪ ip route: Shows or manipulates routing tables.
    ◦ Example: ip addr show: Displays IP addresses.

• ifconfig (Configure network interfaces)
    ◦ Purpose: Configures or displays network interface parameters. Although still widely used, ip is the recommended modern alternative.
    ◦ Example: ifconfig: Prints the IP address and other network interface details.

• ssh (Secure shell for remote login)
    ◦ Purpose: Establishes a secure, encrypted connection between a local and remote machine, allowing secure access and management of remote servers.
    ◦ Explanation: It uses key-based authentication for higher security.
    ◦ Example: ssh username@remote_ip: Connects to a remote server.

• scp (Secure copy files between hosts)
    ◦ Purpose: Securely copies files between hosts over SSH.
    ◦ Example: scp file.txt user@remote:/path/to/destination/: Copies file.txt to a remote server.

• wget (Non-interactive network downloader)
    ◦ Purpose: Downloads files from the internet using HTTP, HTTPS, or FTP protocols. It can download files non-interactively, meaning it can run in the background after initiation.
    ◦ Example: wget https://example.com/file.zip: Downloads file.zip from the specified URL.

• curl (Transfer data with URLs)
    ◦ Purpose: A versatile command-line tool for transferring data to or from a server using various protocols (HTTP, FTP, etc.). It's widely used in scripting for interacting with web services.
    ◦ Example: curl -O https://example.com/file.txt: Downloads file.txt and saves it with the same name.

• netstat (Network statistics)
    ◦ Purpose: Displays active network connections, routing tables, and listening ports. It's considered deprecated in favor of ss.
    ◦ Key Option: -tuln: Shows all listening TCP and UDP ports numerically.
    ◦ Example: netstat -tuln: Displays all listening TCP and UDP ports.

6. User and Group Management
These commands are essential for creating, modifying, and deleting user accounts and groups, and for managing user permissions.
• useradd / adduser (Add a user to the system)
    ◦ Purpose: Creates a new user account on the system.
    ◦ Explanation: adduser is often a more user-friendly wrapper around useradd that also creates a home directory and prompts for password.
    ◦ Examples:
        ▪ sudo useradd username: Creates a user.
        ▪ sudo adduser shawn: Creates a user named "Shawn".
• passwd (Change user password)
    ◦ Purpose: Changes the password for a user account.
    ◦ Example: sudo passwd username: Sets or changes the password for a user.

• userdel (Delete a user account)
    ◦ Purpose: Deletes a user account from the system.
    ◦ Key Option: -r (remove home directory): Deletes the user's home directory and mail spool, which is considered a clean delete.
    ◦ Examples:
        ▪ sudo userdel username: Deletes a user.
        ▪ sudo userdel -r username: Deletes a user and their home directory.

• groupadd (Add a group to the system)
    ◦ Purpose: Creates a new group on the system.
    ◦ Key Option: -g <group_id>: Creates a group with a specific Group ID (GID).
    ◦ Example: sudo groupadd demo: Creates a group named "demo".

• sudo (Execute a command as another user)
    ◦ Purpose: Stands for "Superuser Do," allowing a permitted user to execute a command as another user (usually root) with superuser privileges.
    ◦ Explanation: It requires the user's password for verification and provides administrative access without directly logging in as root.
    ◦ Example: sudo systemctl restart apache2: Restarts the Apache service with root privileges.

• whoami (Print the current logged-in user)
    ◦ Purpose: Displays the username of the current user.
    ◦ Explanation: Equivalent to echo $USER.

• umask (Set default permissions for new files)
    ◦ Purpose: Sets the default permissions for newly created files and directories.
    ◦ Explanation: It specifies restrictions on these permissions, essentially controlling the maximum allowed permissions for new items.
    ◦ Example: umask 022: Sets default permissions such that new files get 644 (rw-r--r--) and new directories get 755 (rwxr-xr-x).

7. System Information and Monitoring
These commands provide insights into your system's hardware, kernel, and overall status.
• uname (Print system information)
    ◦ Purpose: Displays information about the Linux system, such as the kernel name, hostname, kernel release, and machine hardware name.
    ◦ Key Option: -a (all): Shows all available system information.
    ◦ Examples:
        ▪ uname: Prints the kernel name (e.g., Linux).
        ▪ uname -a: Provides comprehensive system information.
        ▪ uname -r: Shows the kernel version.

• hostname (Show or set the system’s hostname)
    ◦ Purpose: Displays or sets the system's hostname.
    ◦ Example: hostname: Shows the current hostname.

• free (Display memory usage)
    ◦ Purpose: Displays the amount of free and used physical memory and swap space in the system.
    ◦ Key Options:
        ▪ -m: Displays memory in megabytes.
        ▪ -h (human-readable): Displays memory in easily readable units.
    ◦ Example: free -m: Shows memory usage in MB.

8. Archiving and Compression
These commands help you create archives (tarballs) and compress files to save disk space or prepare them for transfer.
• tar (Archive files)
    ◦ Purpose: Used to create archive files (often called "tarballs") which group multiple files into a single file. It can also compress these archives.
    ◦ Key Options:
        ▪ -c (create): Creates a new archive.
        ▪ -x (extract): Extracts files from an archive.
        ▪ -v (verbose): Displays the files being processed.
        ▪ -f <archive_file>: Specifies the name of the archive file.
        ▪ -z (gzip): Compresses/decompresses the archive using gzip.
    ◦ Examples:
        ▪ tar -czf archive.tar.gz /path/to/directory: Creates a gzipped tarball from a directory.
        ▪ tar -xvf archive.tar: Extracts a tarball.
        ▪ tar -xzvf jayesh.tar.gz: Decompresses and extracts a gzipped tarball.

• gzip / gunzip (Compress and decompress files)
    ◦ Purpose:
        ▪ gzip: Compresses files using the gzip algorithm, typically adding a .gz extension.
        ▪ gunzip: Decompresses files compressed with gzip.
    ◦ Examples:
        ▪ gzip filename: Compresses filename into filename.gz.
        ▪ gzip -d filename.gz: Decompresses filename.gz back to filename.

9. Package Management (Distribution-Dependent)
These commands are used to install, update, and remove software packages on your Linux system, varying by distribution.
• apt-get (APT package handling utility - Debian-based)
    ◦ Purpose: Manages packages on Debian-based distributions like Ubuntu.
    ◦ Examples:
        ▪ sudo apt-get install <package>: Installs a package.
        ▪ sudo apt-get update: Updates the list of available packages.
        ▪ sudo apt-get upgrade: Upgrades installed packages.
        ▪ sudo apt-get remove <package>: Removes a package.

• yum (Package manager for RPM-based systems - Red Hat-based)
    ◦ Purpose: Manages packages on RPM-based systems like CentOS and older Fedora versions.
    ◦ Examples:
        ▪ sudo yum install <package>: Installs a package. (e.g., sudo yum install net-tools for ifconfig)
        ▪ sudo yum update: Updates installed packages.

• dnf (Next-generation package manager - Fedora, CentOS 8+)
    ◦ Purpose: The successor to yum in modern Fedora and CentOS distributions.
    ◦ Example: sudo dnf install <package>: Installs a package.

10. System Services and Daemon Management
These commands control system services and daemons, which are crucial for managing applications and system functions.
• systemctl (Control the systemd system and service manager)
    ◦ Purpose: The primary command for controlling systemd services and daemons on modern Linux distributions.
    ◦ Key Usage:
        ▪ systemctl start <service>: Starts a service.
        ▪ systemctl stop <service>: Stops a service.
        ▪ systemctl restart <service>: Restarts a service.
        ▪ systemctl enable <service>: Enables a service to start automatically on boot.
        ▪ systemctl disable <service>: Disables a service from starting on boot.
        ▪ systemctl status <service>: Checks the status of a service (running, stopped, etc.).
    ◦ Example: systemctl status apache2: Displays the status of the Apache Web server.

• service (Older service management command)
    ◦ Purpose: Used for managing services in older, non-systemd Linux systems. Still works as a wrapper for systemctl in some modern systems for backward compatibility.

11. Scheduling Tasks
These commands enable you to automate tasks by scheduling them to run at specific times or intervals.
• crontab (Manage cron jobs)
    ◦ Purpose: Manages cron jobs, which are scheduled commands or scripts that run automatically at specified times.
    ◦ Explanation: cron is a daemon that runs scheduled commands, and crontab is the utility to edit, list, and remove these jobs for the current user.
    ◦ Key Usage:
        ▪ crontab -e: Edits cron jobs for the current user.
        ▪ crontab -l: Lists the current user's cron jobs.
        ▪ crontab -r: Removes the current user's cron jobs.
    ◦ Cron Job Format: MIN HOUR DAY_OF_MONTH MONTH DAY_OF_WEEK COMMAND.
    ◦ Example: 30 9 * * * /home/ec2-user/command: Schedules a command to run every day at 9:30 AM.

12. File Permissions and Security
These commands are fundamental for controlling who can read, write, and execute files and directories, ensuring system security.
• chmod (Change file permissions)
    ◦ Purpose: Changes the file permissions of files and directories.
    ◦ Explanation: Permissions are defined for the owner, group, and others and can be Read (r), Write (w), and Execute (x). It supports both symbolic (e.g., u+r, g-w) and numeric (octal) modes.
    ◦ Numeric Modes:
        ▪ r (read) = 4
        ▪ w (write) = 2
        ▪ x (execute) = 1
        ▪ No permission = 0
    ◦ Examples:
        ▪ chmod 755 file.txt: Gives read, write, and execute permissions to the owner, and read-execute permissions to others (rwxr-xr-x).
        ▪ chmod u+wx script.sh: Gives write and executable permissions to the user (owner) for script.sh.

• chown (Change file owner and group)
    ◦ Purpose: Changes the user owner and/or group owner of a file or directory.
    ◦ Example: chown user:group file.txt: Changes the owner of file.txt to user and the group to group1. 

1. Containerization and Orchestration
Containerization is a method of packaging an application and all its dependencies (libraries, configuration files, etc.) into a single, isolated unit called a container. This ensures that the application runs consistently across different environments. Orchestration tools then help manage and scale these containers across multiple servers.

Docker
Docker is a widely used CLI (Command-Line Interface) tool for managing containers. It allows you to create, run, deploy, and manage applications using containers.

Here are the key Docker commands and their purposes:
• docker run <image>: This command is used to run a container from a specified image. For example, docker run ubuntu would start a container based on the Ubuntu image.
• docker ps: Displays a list of all currently running containers.
• docker ps -a: Shows all containers, including those that are stopped.
• docker build -t <image_name> .: This command builds a new Docker image from a Dockerfile in the current directory (.). The -t option allows you to tag the image with a specific name.
• docker exec -it <container_id> bash: Allows you to execute a command inside a running container, typically to start an interactive Bash shell (bash) within it. The -it options provide an interactive pseudo-TTY.
• docker stop <container_id>: Stops a running container gracefully.
• docker rm <container_id>: Removes a stopped container from your system.
• docker logs <container_id>: Used to view the logs generated by a container.
• docker images: Lists all available Docker images on your local machine.
• docker rmi <image_name>: Removes a Docker image from your local machine.
• docker network ls: Lists all Docker networks.
• docker-compose: This is a tool specifically designed to manage multi-container Docker applications. It uses a YAML file to define and configure all the services of your application.
    ◦ docker-compose up: Starts up a multi-container environment defined in the docker-compose.yml file.
    ◦ docker-compose down: Stops and removes containers, networks, and volumes created by docker-compose up.
    ◦ docker-compose logs: Views logs from containers managed by docker-compose.
Kubernetes (k8s)
Kubernetes (k8s) is a powerful container orchestration system that automates the deployment, scaling, and management of containerized applications across clusters of machines.
The primary command-line tool for interacting with Kubernetes clusters is kubectl:
• kubectl get pods: Lists all pods (the smallest deployable units in Kubernetes) in the current namespace.
• kubectl get nodes: Lists all nodes (worker machines) in the Kubernetes cluster.
• kubectl get services: Lists all services (an abstraction that defines a logical set of Pods and a policy by which to access them) in the cluster.
• kubectl apply -f <file>.yaml: Applies a configuration (e.g., a deployment, pod, or service configuration) from a YAML file to the cluster. This command is often preferred for updates as it applies changes incrementally.
• kubectl create -f <file>.yaml: Creates a resource from a file.
• kubectl delete -f <file>.yaml: Deletes a resource defined in a file.
• kubectl exec -it <pod_name> -- bash: Executes a command inside a pod, such as opening an interactive shell (bash).
• kubectl logs <pod_name>: Views the logs of a specific pod.
• kubectl describe pod <pod_name>: Provides detailed information about a pod, including its status, events, and resource usage.
• kubectl scale deployment <deployment_name> --replicas=<number>: Scales a deployment to the desired number of replicas (instances of your application).
• kubectl rollout restart deployment <deployment_name>: Restarts a deployment, often used to apply configuration changes or refresh pods.
• kubectl port-forward pod <pod_name> <local_port>:<remote_port>: Forwards a port from a pod to your local machine, allowing you to access a service running inside the pod from your localhost.

Helm
Helm is known as the Kubernetes package manager. It simplifies the deployment and management of applications on Kubernetes by packaging them into "charts," which are collections of pre-configured Kubernetes resources.
Key Helm commands include:
• helm install <release_name> <chart_name>: Installs a Helm chart into your Kubernetes cluster, creating a "release".
• helm upgrade <release_name> <chart_name>: Upgrades an existing Helm release with a new version of the chart or new configuration values.
• helm list: Lists all deployed Helm releases in your cluster.
• helm delete <release_name>: Deletes a Helm release from your cluster.
• helm search <chart_name>: Searches for Helm charts in configured repositories.
--------------------------------------------------------------------------------
2. Automation and Configuration Management
These tools are crucial for automating repetitive tasks and managing the configuration of servers and infrastructure consistently. They help ensure that your systems are set up and maintained according to predefined standards, reducing manual errors and increasing efficiency.
Ansible
Ansible is an automation tool used for configuration management, application deployment, and task automation. It is agentless, meaning it communicates with target machines over SSH without requiring any special software installed on them.
• ansible all -m ping: This is an example of running an ad-hoc command with Ansible. Here, it uses the ping module (-m ping) to check connectivity to all hosts defined in the Ansible inventory.
• ansible-playbook playbook.yml: This command runs an Ansible playbook, which is a YAML file containing a set of ordered tasks to be executed on specified hosts. Playbooks are central to Ansible's automation capabilities. Other options include --check for a dry-run, --limit <host> to run on specific hosts, and --extra-vars to pass variables.

Terraform
Terraform is an Infrastructure as Code (IaC) tool used for provisioning and managing cloud resources and other infrastructure components. It allows you to define your infrastructure in declarative configuration files.
Terraform follows a clear workflow:
• terraform init: Initializes a working directory containing Terraform configuration files. This command downloads necessary provider plugins.
• terraform plan: Generates an execution plan that shows a preview of what changes Terraform will make to your infrastructure based on your configuration files. It's a critical step for reviewing changes before applying them.
• terraform apply: Applies the changes described in the execution plan to create, update, or delete infrastructure resources.
• terraform destroy: Destroys all infrastructure created by the current Terraform configuration.
• terraform validate: Validates the syntax and configuration files, ensuring they are internally consistent and correct.
• terraform show: Shows the current state of the infrastructure managed by Terraform.
Puppet
Puppet is another configuration management tool that helps automate the configuration and management of systems. It uses a declarative language to describe desired system states.
• puppet apply <manifest.pp>: Applies a Puppet manifest file locally on the system where the command is run. Manifests (.pp files) contain instructions for configuring the system.
• puppet agent --test: Tests the Puppet agent, which can be used to perform a one-off run to apply configurations from a Puppet master server.
• puppet resource: Shows the current state of resources (like files, services, packages) on the system.

--------------------------------------------------------------------------------
3. CI/CD Tools and Commands
CI/CD (Continuous Integration/Continuous Deployment) tools automate the software development lifecycle, from code commit to deployment. They help integrate code changes frequently, run automated tests, and deliver applications reliably and quickly.
Jenkins
Jenkins is a popular open-source continuous integration (CI) tool. It allows developers to continuously integrate code changes into a central repository and then automatically build, test, and deploy the code.
• java -jar jenkins.war: This command is used to start the Jenkins server from its WAR (Web Application Archive) file.
• By default, Jenkins is typically accessed through a web browser at http://localhost:8080 after it's started.
GitLab CI
GitLab CI is an integrated CI/CD service within GitLab. It uses a configuration file in your repository to define pipelines that automatically build, test, and deploy your code.
• .gitlab-ci.yml: This is the configuration file for GitLab CI/CD pipelines. It typically resides at the root of your Git repository and defines the stages, jobs, and scripts for your CI/CD workflow.
• gitlab-runner register: Used to register a new runner with GitLab. Runners are agents that execute the jobs defined in your CI/CD pipelines.
• gitlab-runner run: Command to run the GitLab Runner to process jobs assigned to it.
GitHub Actions
GitHub Actions is a CI/CD feature integrated directly into GitHub. It allows you to automate workflows directly within your GitHub repository.
• GitHub Actions workflows are defined using YAML configuration files, which are typically located in the .github/workflows/ directory within your repository.
• actions/checkout@v2: An example of a common action used to check out the repository code into your CI pipeline, making your code available for subsequent steps.
• actions/setup-node@v2: An example action to set up a specific version of Node.js for use in a pipeline, useful for JavaScript-based projects.
• docker/setup-buildx-action@v1: An example action to set up Docker Buildx for building multi-platform Docker images.
GitHub Actions: Uses YAML files in .github/workflows/.
Kubernetes (k8s)
Kubernetes (k8s) is a powerful container orchestration system that automates the deployment, scaling, and management of containerized applications across clusters of machines.
The primary command-line tool for interacting with Kubernetes clusters is kubectl:
• kubectl get pods: Lists all pods (the smallest deployable units in Kubernetes) in the current namespace.
• kubectl get nodes: Lists all nodes (worker machines) in the Kubernetes cluster.
• kubectl get services: Lists all services (an abstraction that defines a logical set of Pods and a policy by which to access them) in the cluster.
• kubectl apply -f <file>.yaml: Applies a configuration (e.g., a deployment, pod, or service configuration) from a YAML file to the cluster. This command is often preferred for updates as it applies changes incrementally.
• kubectl create -f <file>.yaml: Creates a resource from a file.
• kubectl delete -f <file>.yaml: Deletes a resource defined in a file.
• kubectl exec -it <pod_name> -- bash: Executes a command inside a pod, such as opening an interactive shell (bash).
• kubectl logs <pod_name>: Views the logs of a specific pod.
• kubectl describe pod <pod_name>: Provides detailed information about a pod, including its status, events, and resource usage.
• kubectl scale deployment <deployment_name> --replicas=<number>: Scales a deployment to the desired number of replicas (instances of your application).
• kubectl rollout restart deployment <deployment_name>: Restarts a deployment, often used to apply configuration changes or refresh pods.
• kubectl port-forward pod <pod_name> <local_port>:<remote_port>: Forwards a port from a pod to your local machine, allowing you to access a service running inside the pod from your localhost.
Helm
Helm is known as the Kubernetes package manager. It simplifies the deployment and management of applications on Kubernetes by packaging them into "charts," which are collections of pre-configured Kubernetes resources.
Key Helm commands include:
• helm install <release_name> <chart_name>: Installs a Helm chart into your Kubernetes cluster, creating a "release".
• helm upgrade <release_name> <chart_name>: Upgrades an existing Helm release with a new version of the chart or new configuration values.
• helm list: Lists all deployed Helm releases in your cluster.
• helm delete <release_name>: Deletes a Helm release from your cluster.
• helm search <chart_name>: Searches for Helm charts in configured repositories.

--------------------------------------------------------------------------------
2. Automation and Configuration Management
These tools are crucial for automating repetitive tasks and managing the configuration of servers and infrastructure consistently. They help ensure that your systems are set up and maintained according to predefined standards, reducing manual errors and increasing efficiency.
Ansible
Ansible is an automation tool used for configuration management, application deployment, and task automation. It is agentless, meaning it communicates with target machines over SSH without requiring any special software installed on them.
• ansible all -m ping: This is an example of running an ad-hoc command with Ansible. Here, it uses the ping module (-m ping) to check connectivity to all hosts defined in the Ansible inventory.
• ansible-playbook playbook.yml: This command runs an Ansible playbook, which is a YAML file containing a set of ordered tasks to be executed on specified hosts. Playbooks are central to Ansible's automation capabilities. Other options include --check for a dry-run, --limit <host> to run on specific hosts, and --extra-vars to pass variables.
Terraform
Terraform is an Infrastructure as Code (IaC) tool used for provisioning and managing cloud resources and other infrastructure components. It allows you to define your infrastructure in declarative configuration files.
Terraform follows a clear workflow:
• terraform init: Initializes a working directory containing Terraform configuration files. This command downloads necessary provider plugins.
• terraform plan: Generates an execution plan that shows a preview of what changes Terraform will make to your infrastructure based on your configuration files. It's a critical step for reviewing changes before applying them.
• terraform apply: Applies the changes described in the execution plan to create, update, or delete infrastructure resources.
• terraform destroy: Destroys all infrastructure created by the current Terraform configuration.
• terraform validate: Validates the syntax and configuration files, ensuring they are internally consistent and correct.
• terraform show: Shows the current state of the infrastructure managed by Terraform.
Puppet
Puppet is another configuration management tool that helps automate the configuration and management of systems. It uses a declarative language to describe desired system states.
• puppet apply <manifest.pp>: Applies a Puppet manifest file locally on the system where the command is run. Manifests (.pp files) contain instructions for configuring the system.
• puppet agent --test: Tests the Puppet agent, which can be used to perform a one-off run to apply configurations from a Puppet master server.
• puppet resource: Shows the current state of resources (like files, services, packages) on the system.

--------------------------------------------------------------------------------
3. CI/CD Tools and Commands
CI/CD (Continuous Integration/Continuous Deployment) tools automate the software development lifecycle, from code commit to deployment. They help integrate code changes frequently, run automated tests, and deliver applications reliably and quickly.
Jenkins
Jenkins is a popular open-source continuous integration (CI) tool. It allows developers to continuously integrate code changes into a central repository and then automatically build, test, and deploy the code.
• java -jar jenkins.war: This command is used to start the Jenkins server from its WAR (Web Application Archive) file.
• By default, Jenkins is typically accessed through a web browser at http://localhost:8080 after it's started.
GitLab CI
GitLab CI is an integrated CI/CD service within GitLab. It uses a configuration file in your repository to define pipelines that automatically build, test, and deploy your code.
• .gitlab-ci.yml: This is the configuration file for GitLab CI/CD pipelines. It typically resides at the root of your Git repository and defines the stages, jobs, and scripts for your CI/CD workflow.
• gitlab-runner register: Used to register a new runner with GitLab. Runners are agents that execute the jobs defined in your CI/CD pipelines.
• gitlab-runner run: Command to run the GitLab Runner to process jobs assigned to it.
GitHub Actions
GitHub Actions is a CI/CD feature integrated directly into GitHub. It allows you to automate workflows directly within your GitHub repository.
• GitHub Actions workflows are defined using YAML configuration files, which are typically located in the .github/workflows/ directory within your repository.
• actions/checkout@v2: An example of a common action used to check out the repository code into your CI pipeline, making your code available for subsequent steps.
• actions/setup-node@v2: An example action to set up a specific version of Node.js for use in a pipeline, useful for JavaScript-based projects.
• docker/setup-buildx-action@v1: An example action to set up Docker Buildx for building multi-platform Docker images.

Cloud Service Command Line Interfaces (CLIs) are powerful tools that allow you to manage various cloud services directly from your terminal, providing an efficient way to interact with your cloud resources without a graphical interface. The sources highlight specific CLIs for Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP).

Here's a more detailed explanation of the commands for each cloud service CLI:
AWS CLI (aws)
The aws command-line tool is designed for managing Amazon Web Services. It enables you to interact with a wide range of AWS services programmatically.

• aws configure: This command is used to configure your AWS CLI with your credentials, such as your AWS Access Key ID, Secret Access Key, default region, and output format. This setup is crucial for the CLI to authenticate and interact with your AWS account.

• aws s3 cp: This command allows you to copy files to or from an Amazon S3 (Simple Storage Service) bucket. For example, aws s3 cp file.txt s3://bucket-name/ would copy file.txt to the specified S3 bucket.

• aws s3 sync: This command is used to synchronize directories with an S3 bucket. It efficiently copies new or modified files from the source to the destination, and can also delete files at the destination that are not present in the source, depending on options.

• aws ec2 describe-instances: Use this command to retrieve and display detailed information about your Amazon EC2 (Elastic Compute Cloud) instances, including their status, instance type, IP addresses, and more.

• aws ec2 start-instances --instance-ids <id>: This command is used to start one or more stopped EC2 instances, specified by their instance IDs.

• aws ec2 stop-instances --instance-ids <id>: Conversely, this command allows you to stop one or more running EC2 instances, specified by their instance IDs.
Azure CLI (az)
The az command-line tool is used for managing Microsoft Azure services. It provides commands to create, configure, and manage Azure resources.

• az login: This command is essential for logging into your Azure account from the CLI. It typically opens a browser window for authentication and then securely connects your terminal session to your Azure subscription.

• az vm list: Use this command to list all virtual machines within your Azure subscriptions or within a specific resource group.

• az vm start --name <vm_name> --resource-group <resource_group>: This command allows you to start an Azure virtual machine, requiring you to specify the VM's name and the resource group it belongs to.

• az storage blob upload: This command is used to upload files to Azure Blob Storage, which is Azure's object storage solution.

• az group create: You can use this command to create a new resource group in Azure. Resource groups act as logical containers for your Azure resources.

Google Cloud SDK (gcloud)
The gcloud command-line tool is part of the Google Cloud SDK and is used for managing Google Cloud Platform (GCP) services.
• gcloud auth login: This command is used to log in to Google Cloud and authenticate your gcloud session. It will open a browser window to complete the authentication process.

• gcloud compute instances list: This command allows you to list compute instances (virtual machines) that you have provisioned in Google Compute Engine.

• gcloud compute instances stop <instance_name>: Use this command to stop a specific Google Cloud VM instance, identified by its name.

• gcloud app browse: This command is specifically for Google App Engine applications and will open the current Google App Engine application in a web browser.

5. Logging and Monitoring
Logging and monitoring are critical aspects of managing any system, especially in cloud and DevOps environments, as they provide visibility into system health, performance, and potential issues. 

The sources introduce several popular tools for these purposes:
• Prometheus: This is an open-source system monitoring and alerting toolkit. It is used to collect metrics from various targets, store them, and then allow for querying and alerting based on these metrics. You would typically start the Prometheus server (often as a background service) or by specifying a configuration file using prometheus --config.file=<config_file>.

• Grafana: This tool is primarily used for visualizing monitoring data. Grafana integrates well with Prometheus and other data sources to create dashboards that display metrics, logs, and traces in an easily understandable format. You can manage Grafana plugins using the grafana-cli command, for example, grafana-cli plugins install <plugin-name>.

• ELK Stack (Elasticsearch, Logstash, Kibana): This is a powerful suite of tools for logging, searching, and analyzing large volumes of data.
    ◦ Elasticsearch acts as a search engine for logging and data analytics. You can check its cluster health status using a curl command like curl -XGET 'localhost:9200/_cluster/health?pretty'.
    ◦ Logstash is a server-side data processing pipeline that ingests data from multiple sources, transforms it, and then sends it to a "stash," like Elasticsearch. It is run with a specified configuration file, for example, logstash -f <config_file>.
    ◦ Kibana provides a web interface for visualizing Elasticsearch data. It allows users to create dashboards, perform searches, and analyze log and event data. Kibana is typically accessed through a web browser (e.g., http://localhost:5601).

Troubleshooting and Security
These sections highlight common challenges and best practices for maintaining the health and security of Linux systems.

Troubleshooting
Troubleshooting involves diagnosing and resolving issues to ensure system stability and performance.
• Network Connectivity Issues: When facing network problems, several steps can be taken:
    ◦ First, check the physical internet connection and cables.
    ◦ Verify the network configuration by checking the IP address of the network interface using ip addr or ifconfig.
    ◦ Ensure the default gateway is set correctly with ip route.
    ◦ Verify DNS server configuration in the /etc/resolv.conf file.
    ◦ Check and modify firewall rules using commands like ufw or iptables.
    ◦ You might need to restart your network interface using ifup and ifdown commands, followed by a system reboot.
    ◦ Tools like ping can test connectivity to remote hosts and traceroute can trace the route packets take.

• Boot Failure: If a Linux system fails to boot, consider these diagnostic steps:
    ◦ Check warning and error messages displayed during the boot process.
    ◦ Review boot logs to pinpoint the exact issue.
    ◦ Inspect GRUB bootloader options for misconfigurations.
    ◦ Check hardware connections, including cables, RAM, and cooling fans.
    ◦ If a Kernel-related error appears, try booting with an older Kernel version from GRUB.
    ◦ Identify any recent system changes that might have caused the failure.

• Slow Performance: To troubleshoot a slow-performing Linux server:
    ◦ Update the system to the latest available versions.
    ◦ Optimize disk usage, enable caching, and optimize access patterns.
    ◦ Actively manage memory and CPU usage.
    ◦ Disable unnecessary services and consider using lightweight alternatives for tools.
    ◦ Monitor system resources regularly using tools like top (displays real-time CPU & memory usage) or htop (an interactive and more user-friendly process viewer).
    ◦ Perform Kernel parameter tune-up.
    ◦ Tools like Performance Co-Pilot (PCP) can also be used to monitor system-level performance.
• File Permissions Issues: These often arise from:
    ◦ Incorrect ownership of files or directories.
    ◦ Improper permissions set for users or groups.
    ◦ Conflicts between different users' permissions.
    ◦ Commands like chmod (change permissions), chown (change owner and group), and chgrp (change group ownership) are used to manage these.

• Out of Memory: A Linux system can run out of memory due to:
    ◦ Memory leaks in applications.
    ◦ Excessive memory usage by running processes.
    ◦ Inadequate memory allocation.
    ◦ High memory demands from large datasets.
    ◦ The free command shows RAM status. top and htop can help identify processes consuming a lot of memory.

• Out of Disk Space: Common causes include:
    ◦ Large log files.
    ◦ Excessive data storage.
    ◦ Uncontrolled growth of temporary files.
    ◦ Improper cleanup of old files.
    ◦ Runaway processes generating excessive output.
    ◦ The df command reports file system disk space usage (df -h for human-readable format), and du estimates file space usage (du -h for human-readable, du -sh for summary).
Security
Securing a Linux server is crucial to protect against threats and unauthorized access:

• Secure a Linux Server: Key methods to secure a Linux server include:
    ◦ Creating strong passwords.
    ◦ Updating the server regularly and applying security patches.
    ◦ Using secure protocols like SSH and configuring it for key-based authentication for higher security.
    ◦ Implementing intrusion detection systems (IDS) to monitor network traffic for malicious activities.
    ◦ Configuring firewalls (e.g., iptables, firewalld, ufw) to limit inbound and outbound traffic.
    ◦ Disabling all unused network services.
    ◦ Creating regular backups.
    ◦ Reviewing logs and performing regular security audits.
    ◦ Encrypting network traffic and enabling monitoring.

• SELinux: Stands for Security-Enhanced Linux, which is an additional security framework. It offers an extra layer of security to improve access control and strengthen overall system security, preventing unauthorized access and exploitation. However, understanding SELinux is essential before working with it, as misconfigurations can lead to serious security issues.


Here are the detailed explanations for each concept:
• Operating System (OS)
    ◦ An OS acts as a bridge that connects the software (applications) with the hardware(CPU, RAM, disk, etc.), managing all interactions between them.
    ◦ For instance, when you install an application like Jenkins, it requests resources from the OS, which then communicates with the hardware to allocate those resources and sends them back to the application, allowing it to function.
    ◦ OS is considered system softwarethat controls hardware and provides a platform for other software.

• Kernel
    ◦ The Kernel is the core or "heart" of Linux. It is a low-level software system that directly communicates with hardwarelike the CPU, memory, and various devices.
    ◦ Its primary responsibilities include:
        ▪ Device management(handling hardware like USB and keyboards).
        ▪ Memory management(allocating RAM).
        ▪ Process management(controlling running applications).
        ▪ Handling system calls(allowing applications to communicate with the kernel).
    ◦ The kernel also tracks system resources and provides a user interface. It is legal to edit the Linux kernel because it is released under the GPL (General Public License).

• Shell
    ◦ The Shell serves as an interface between the user and the kernel. It takes user commands, typically entered via the Command Line Interface (CLI), and translates them into instructions that the kernel can understand and execute.
    ◦ Common types of shells include:
        ▪ /bin/bash(Bourne Again Shell), which is the default and a more powerful shell for Linux.
        ▪ /bin/sh(Basic shell).
        ▪ /bin/ksh(Korn shell), a high-level shell for programming.
        ▪ csh(C Shell), zsh(Z Shell), and fish(Friendly Interactive Shell), each with unique features.
    ◦ You can check the current shell using echo $SHELLor echo $0and list all available shells with cat /etc/shells.

• Distribution (Distro)
    ◦ A Distribution is a specific version or "flavor" of Linux. These distros are tailored for different purposes, user skill levels, and environments.
    ◦ Popular examples include Ubuntu(user-friendly), Red Hat (RHEL)(for enterprises), CentOS(formerly popular for servers, now largely replaced by AlmaLinux/Rocky Linux), Debian, Alpine, Fedora, and Arch Linux.

• Open Source
    ◦ Describes software for which the source code is freely available for anyone to modify, improve, and distribute. Linux is a prime example of free and open-source software.

• Monolithic Kernel
    ◦ A type of kernel architecture where all operating system services, such as device drivers, memory management, and process management, run together in the kernel space. Linux uses a monolithic kernel.

• Microkernel
    ◦ In contrast to a monolithic kernel, a Microkernel architecture means that only basic operating system services (like inter-process communication and low-level memory management) run in the kernel space, while other services (such as device drivers and file systems) run in user space. Windows operating systems typically use a microkernel architecture.

• File System Case Sensitivity
    ◦ Refers to how a file system handles names with different capitalization. In Linux, the file system is case-sensitive, meaning "file.txt" and "File.txt" are treated as two distinct files. This differs from Windows, where file systems are case-insensitive.
• File Permissions
    ◦ These are crucial access controls in Linux that define who can do what with a file or directory. The three primary types of permissions are:
        ▪ Read (r):Allows users to open and view the contents of a file.
        ▪ Write (w):Allows users to modify or delete a file.
        ▪ Execute (x):Allows users to run a file (if it's a script or program) or access a directory.
    ◦ These permissions are typically assigned for three categories: the ownerof the file, the groupthe file belongs to, and others(everyone else). The chmodcommand is used to change file permissions.

• Root Account
    ◦ The Root account is the system administrator account in Linux, often referred to as "superuser," with complete system control. It has a unique User ID (UID) of 0. This account has unparalleled privileges to perform any task on the system.

• CLI (Command Line Interface)
    ◦ A text-based interface for interacting with the operating system. Users type commands, which the system then executes. The CLI is essential for server management because most servers operate without a graphical interface.

• GUI (Graphical User Interface)
    ◦ A visual interface for interacting with the operating system, characterized by icons, menus, and windows, which can be manipulated using a mouse. It provides an intuitive and user-friendly way to operate a system, in contrast to the CLI.

• Swap Space
    ◦ This is a dedicated space on a hard drive or SSD that Linux uses as an extension of physical RAM. When the physical memory (RAM) is full, the OS moves less-used data from RAM to swap space, freeing up RAM for active processes. This helps the system cope with a lack of physical memory and temporarily stores concurrently running programs.

• Hard Link
    ◦ A direct reference to a file's inode(the data structure that stores file metadata). Multiple hard links can point to the same inode, effectively making them equal references to the same file data. Deleting one hard link does not affect the file or other hard linkspointing to it. Hard links share similar inode numbers and use less memory than soft links. They are created using the lncommand without the -soption.

• Soft Link (Symbolic Link)
    ◦ Also known as a symlink, a soft link is a shortcut or a pointer to another file or directory's path. It creates a separate file that contains the path to the original file's location. Unlike hard links, soft links have different inode numbers, can link directories, and typically use more memory. If the original file is deleted, the soft link will break. Soft links are created using the ln -scommand.

• Standard Streams
    ◦ In Linux, input and output are handled through three standard streams:
        ▪ stdin (standard input):The channel for a program to receive input.
        ▪ stdout (standard output):The channel for a program to send its normal output.
        ▪ stderr (standard error):The channel for a program to send error messages.
    ◦ These streams facilitate communication between programs and their environment.

• Process
    ◦ An independent program instancethat is currently executing. Each process has its own memory space and resources, making it independent and not sharing memory with other processes. Processes generally have higher creation and termination times compared to threads.

• Thread
    ◦ A unit of execution within a process. Threads within the same process share the same memory space and resources, making them dependent on each other. They have lower creation and termination times and require fewer resources than processes.

• PID (Process ID)
    ◦ A unique numerical identifier assigned to each running processon a Linux system. This ID is used to manage, monitor, and control individual processes (e.g., using killcommand). You can view a process's PID using ps, pgrep, or echo $$(for the current shell's PID).
• Inode (Index Node)
    ◦ A data structure in a Linux file system that stores metadata about a file or directory. This metadata includes information like permissions, owner, group, size, timestamps (creation, modification, access), and the link count (number of hard links). Crucially, the inode does not store the file's name or its actual data content. Every file has a unique inode number associated with it.

• Mount Point
    ◦ A directory where a filesystem is attached to make its contents accessibleto the operating system. When a device (like a hard drive partition, USB drive, or network share) is mounted to a specific directory, the files and directories on that device become available through that mount point. The mountand umountcommands are used for this purpose.

• Virtual Memory
    ◦ A memory management technique that uses disk space as an extension of physical RAM. This allows a system to compensate for a lack of physical memory by temporarily transferring data between RAM and disk storage. Both software and hardware utilize virtual memory.

• Process Scheduling
    ◦ The mechanism within the operating system that determines the order and execution time of concurrent processesrunning on the system. The Linux process scheduler is priority-based and uses a preemptive algorithm to allocate CPU time efficiently, ensuring fair resource usage among multiple applications.

• Netfilter
    ◦ A framework within the Linux kernel that provides facilities for network packet filtering, network address translation (NAT), and other packet manipulation functions. It is the underlying technology for firewall administration tools like iptablesand nftables.

• iptables vs. nftables
    ◦ iptablesis an older, chain-based command-line utility for configuring Netfilter firewall rules, primarily for IPv4 packet filtering and NAT. Rules defined by iptablesare not persistent across reboots by default unless saved.
    ◦ nftablesis a newer, more flexible, and consolidated packet filtering frameworkthat also leverages the Netfilter kernel framework. It is designed to replace iptablesand ebtables, offering a more efficient and expressive syntax.

• QoS (Quality of Service)
    ◦ Refers to the management of network resources to prioritize certain types of network trafficover others. This is used to ensure that critical applications or data streams (e.g., voice or video) receive sufficient bandwidth and lower latency.

• TCP Congestion Control
    ◦ A set of algorithms implemented within the TCP (Transmission Control Protocol) stack to prevent network congestion. These algorithms dynamically adjust the rate at which data is sent to avoid overwhelming the network and causing packet loss.

• Network Namespaces
    ◦ A Linux kernel feature that isolates network resources for different processes or groups of processes. Each network namespace has its own network interfaces, IP addresses, routing tables, and firewall rules, providing network isolation similar to virtual machines but for individual processes. This is a key technology for containerization.

• eBPF (extended Berkeley Packet Filter)
    ◦ A powerful technology that allows for running custom, sandboxed programs in the Linux kernel. It enhances capabilities in various areas, including networking, security, and observability, by allowing users to programmatically extend kernel functionality without modifying kernel source code.

• cgroups (control groups)
    ◦ A Linux kernel feature that organizes processes into hierarchical groups for the purpose of resource management. Cgroups allow administrators to allocate, limit, and prioritize resources such as CPU, memory, network bandwidth, and disk I/O for these process groups.

• SMTP (Simple Mail Transfer Protocol)
    ◦ A set of communication guidelines that enables software to transmit electronic mail online. Its primary purpose is to define rules for communication between email servers. It uses two models: end-to-end (connecting different organizations) and store-and-forward (within an organization).

• Absolute Path
    ◦ A method of specifying the exact location of a file or directory from the root directory ("/"). An absolute path always starts with a forward slash /. Example: /home/user/jayesh/geeksforgeeks.txt.

• Relative Path
    ◦ A method of specifying the location of a file or directory relative to the current working directory. Unlike absolute paths, relative paths do not start with a forward slash. Example: documents/file.txt.

• Boot Process
    ◦ Refers to the sequence of stages a Linux system goes through from the moment it is powered on until the operating system is fully loaded and ready for user interaction. The initprocess (or systemdin modern Linux) is the first process launched during boot, with PID 1, and is responsible for initializing the rest of the system.

• SELinux (Security-Enhanced Linux)
    ◦ A security framework that provides an additional layer of security on top of traditional Linux discretionary access controls. It enhances access control and strengthens security by enforcing mandatory access control (MAC) policies, thereby preventing unauthorized access and exploitation.

• Network Bonding
    ◦ The process of combining two or more network interfaces into a single logical interface. This is done to improve network redundancy (if one interface fails, the others can take over) and performance (by increasing bandwidth and throughput).

